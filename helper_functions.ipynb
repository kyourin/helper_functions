{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helper_functions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDYeCeoRaS2F"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVmDKrNaVr9-"
      },
      "source": [
        "# Create an helper function to import an image and resize it to be able to be used with our model\n",
        "\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "\n",
        "  # read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode the read file into a tensor\n",
        "  img = tf.image.decode_image(img)\n",
        "  # resize the image\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "  # rescale the image\n",
        "  img = img/255.\n",
        "  \n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZP11vWqVxAy"
      },
      "source": [
        "def pred_and_plot(model, filename, class_names):\n",
        "  \n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar-CLjTVemDi"
      },
      "source": [
        "**Note:** Yukarıdaki 2 fonksiyon beraber kullanılmalıdırlar!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb_xwmWdj-es",
        "outputId": "7ce475a8-1648-4908-e27b-791b47e12d29"
      },
      "source": [
        "### Data \"augmentation\" (example)\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Get the data\n",
        "\n",
        "import zipfile\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
        "\n",
        "# unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "\n",
        "train_dir = \"/content/pizza_steak/train\"\n",
        "\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range = 0.2,\n",
        "                                             shear_range = 0.2,\n",
        "                                             zoom_range = 0.2,\n",
        "                                             width_shift_range = 0.2,\n",
        "                                             height_shift_range = 0.2,\n",
        "                                             horizontal_flip = True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                   target_size = (224,224),\n",
        "                                                                   batch_size = 32,\n",
        "                                                                   class_mode = \"binary\",\n",
        "                                                                   shuffle = True) # If we want shuffle adjustments, we do that in here..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-05 16:49:23--  https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.112, 142.250.73.208, 142.250.73.240, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109579078 (105M) [application/zip]\n",
            "Saving to: ‘pizza_steak.zip.1’\n",
            "\n",
            "pizza_steak.zip.1   100%[===================>] 104.50M   207MB/s    in 0.5s    \n",
            "\n",
            "2021-07-05 16:49:24 (207 MB/s) - ‘pizza_steak.zip.1’ saved [109579078/109579078]\n",
            "\n",
            "Found 1500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzYAacWtkE_f"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cyld07VaQKh"
      },
      "source": [
        "# Create a TensorBoard callback (we'll functionize this callback as we'll use it later on again and again)\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir)\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6rHeo-gAeKS"
      },
      "source": [
        "# Making a create_model() function to create a model from a URL\n",
        "\n",
        "def create_model(model_url, num_classes = 10):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in the output layer, should be equal to the number of target classes, default 10.\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature extractor layer and Dense output layer with num_classes output neurons.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "\n",
        "  feature_extraction_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False, #Freeze the already learned patterns.\n",
        "                                           name = \"feature_extraction_layer\",\n",
        "                                           input_shape = IMAGE_SHAPE+(3,)) \n",
        "  \n",
        "  # Creating the model\n",
        "  model = tf.keras.models.Sequential([\n",
        "    feature_extraction_layer,\n",
        "    layers.Dense(num_classes, activation=\"softmax\", name = \"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgNp1agCAhuI"
      },
      "source": [
        "# Function to plot the loss curves\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "  epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label=\"training loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"validation loss\")\n",
        "  plt.title(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label=\"training accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"validation accuracy\")\n",
        "  plt.title(\"accuracy\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.legend;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdBdEMoOUDdo"
      },
      "source": [
        "# Creating a function to compare training histories\n",
        "\n",
        "def compare_histories(original_history, new_history, initial_epoch = 5):\n",
        "  # Get original history measurements\n",
        "  acc = original_history.history[\"accuracy\"]\n",
        "  loss = original_history.history[\"loss\"]\n",
        "\n",
        "  val_acc = original_history.history[\"val_accuracy\"]\n",
        "  val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "  # Combine original history metrics with new_history metrics\n",
        "  total_acc = acc + new_history.history[\"accuracy\"]\n",
        "  total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "  total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "  total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "  # Make plots\n",
        "  plt.figure(figsize = (8,8))\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(total_acc, label = \"Training Accuracy\")\n",
        "  plt.plot(total_val_acc, label = \"Validation Accuracy\")\n",
        "  plt.plot([initial_epoch - 1, initial_epoch - 1], plt.ylim(), label = \"Start Fine Tuning\")\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.title(\"Training and validation accuracy\")\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(total_loss, label = \"Training Loss\")\n",
        "  plt.plot(total_val_loss, label = \"Validation Loss\")\n",
        "  plt.plot([initial_epoch - 1, initial_epoch - 1], plt.ylim(), label = \"Start Fine Tuning\")\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.title(\"Training and validation Loss\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}